
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Gotta be SAFE: a new framework for molecular design">
      
      
      
        <link rel="canonical" href="https://github.com/datamol-io/safe/0.1.4/api/safe.models.html">
      
      
        <link rel="prev" href="safe.viz.html">
      
      
        <link rel="next" href="../cli.html">
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.5.3">
    
    
      
        <title>Model training - SAFE</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.50c56a3b.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#config-file" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <div data-md-color-scheme="default" data-md-component="outdated" hidden>
        
      </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../index.html" title="SAFE" class="md-header__button md-logo" aria-label="SAFE" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            SAFE
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Model training
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/datamol-io/safe" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    datamol-io/safe
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../index.html" title="SAFE" class="md-nav__button md-logo" aria-label="SAFE" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    SAFE
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/datamol-io/safe" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    datamol-io/safe
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../index.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Tutorials
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Tutorials
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/getting-started.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Getting Started with SAFE
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/design-with-safe.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Molecular design
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/how-it-works.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    How SAFE encoding works?
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/extracting-representation-molfeat.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    so really we just need our custom converter
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    API
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            API
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="safe.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    SAFE
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="safe.viz.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Visualization
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Model training
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="safe.models.html" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Model training
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#config-file" class="md-nav__link">
    <span class="md-ellipsis">
      Config File
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#safe-model" class="md-nav__link">
    <span class="md-ellipsis">
      SAFE Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#safe.trainer.model" class="md-nav__link">
    <span class="md-ellipsis">
      model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#safe.trainer.model.PropertyHead" class="md-nav__link">
    <span class="md-ellipsis">
      PropertyHead
    </span>
  </a>
  
    <nav class="md-nav" aria-label="PropertyHead">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#safe.trainer.model.PropertyHead.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward()
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#safe.trainer.model.SAFEDoubleHeadsModel" class="md-nav__link">
    <span class="md-ellipsis">
      SAFEDoubleHeadsModel
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SAFEDoubleHeadsModel">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#safe.trainer.model.SAFEDoubleHeadsModel.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward()
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#trainer" class="md-nav__link">
    <span class="md-ellipsis">
      Trainer
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#safe.trainer.trainer_utils" class="md-nav__link">
    <span class="md-ellipsis">
      trainer_utils
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#safe.trainer.trainer_utils.SAFETrainer" class="md-nav__link">
    <span class="md-ellipsis">
      SAFETrainer
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SAFETrainer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#safe.trainer.trainer_utils.SAFETrainer.compute_loss" class="md-nav__link">
    <span class="md-ellipsis">
      compute_loss()
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#data-collator" class="md-nav__link">
    <span class="md-ellipsis">
      Data Collator
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#safe.trainer.collator" class="md-nav__link">
    <span class="md-ellipsis">
      collator
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#safe.trainer.collator.SAFECollator" class="md-nav__link">
    <span class="md-ellipsis">
      SAFECollator
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SAFECollator">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#safe.trainer.collator.SAFECollator.__call__" class="md-nav__link">
    <span class="md-ellipsis">
      __call__()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#safe.trainer.collator.SAFECollator.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#safe.trainer.collator.SAFECollator.get_tokenizer" class="md-nav__link">
    <span class="md-ellipsis">
      get_tokenizer()
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#data-utils" class="md-nav__link">
    <span class="md-ellipsis">
      Data Utils
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#safe.trainer.data_utils" class="md-nav__link">
    <span class="md-ellipsis">
      data_utils
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#safe.trainer.data_utils.get_dataset" class="md-nav__link">
    <span class="md-ellipsis">
      get_dataset()
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#safe.trainer.data_utils.get_dataset_column_names" class="md-nav__link">
    <span class="md-ellipsis">
      get_dataset_column_names()
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#safe.trainer.data_utils.take" class="md-nav__link">
    <span class="md-ellipsis">
      take()
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#safe.trainer.data_utils.tokenize_fn" class="md-nav__link">
    <span class="md-ellipsis">
      tokenize_fn()
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../cli.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    CLI
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../license.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    License
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../data_license.html" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Data License
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#config-file" class="md-nav__link">
    <span class="md-ellipsis">
      Config File
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#safe-model" class="md-nav__link">
    <span class="md-ellipsis">
      SAFE Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#safe.trainer.model" class="md-nav__link">
    <span class="md-ellipsis">
      model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#safe.trainer.model.PropertyHead" class="md-nav__link">
    <span class="md-ellipsis">
      PropertyHead
    </span>
  </a>
  
    <nav class="md-nav" aria-label="PropertyHead">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#safe.trainer.model.PropertyHead.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward()
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#safe.trainer.model.SAFEDoubleHeadsModel" class="md-nav__link">
    <span class="md-ellipsis">
      SAFEDoubleHeadsModel
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SAFEDoubleHeadsModel">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#safe.trainer.model.SAFEDoubleHeadsModel.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward()
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#trainer" class="md-nav__link">
    <span class="md-ellipsis">
      Trainer
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#safe.trainer.trainer_utils" class="md-nav__link">
    <span class="md-ellipsis">
      trainer_utils
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#safe.trainer.trainer_utils.SAFETrainer" class="md-nav__link">
    <span class="md-ellipsis">
      SAFETrainer
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SAFETrainer">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#safe.trainer.trainer_utils.SAFETrainer.compute_loss" class="md-nav__link">
    <span class="md-ellipsis">
      compute_loss()
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#data-collator" class="md-nav__link">
    <span class="md-ellipsis">
      Data Collator
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#safe.trainer.collator" class="md-nav__link">
    <span class="md-ellipsis">
      collator
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#safe.trainer.collator.SAFECollator" class="md-nav__link">
    <span class="md-ellipsis">
      SAFECollator
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SAFECollator">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#safe.trainer.collator.SAFECollator.__call__" class="md-nav__link">
    <span class="md-ellipsis">
      __call__()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#safe.trainer.collator.SAFECollator.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      __init__()
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#safe.trainer.collator.SAFECollator.get_tokenizer" class="md-nav__link">
    <span class="md-ellipsis">
      get_tokenizer()
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#data-utils" class="md-nav__link">
    <span class="md-ellipsis">
      Data Utils
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#safe.trainer.data_utils" class="md-nav__link">
    <span class="md-ellipsis">
      data_utils
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#safe.trainer.data_utils.get_dataset" class="md-nav__link">
    <span class="md-ellipsis">
      get_dataset()
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#safe.trainer.data_utils.get_dataset_column_names" class="md-nav__link">
    <span class="md-ellipsis">
      get_dataset_column_names()
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#safe.trainer.data_utils.take" class="md-nav__link">
    <span class="md-ellipsis">
      take()
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#safe.trainer.data_utils.tokenize_fn" class="md-nav__link">
    <span class="md-ellipsis">
      tokenize_fn()
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


  <h1>Model training</h1>

<h2 id="config-file">Config File<a class="headerlink" href="#config-file" title="Permanent link">&para;</a></h2>
<p>The input config file for training a <code>SAFE</code> model is very similar to the GPT2 config file, with the addition of an optional <code>num_labels</code> attribute for training with descriptors regularization.</p>
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;activation_function&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;gelu_new&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;attn_pdrop&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">0.1</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;bos_token_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">10000</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;embd_pdrop&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">0.1</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;eos_token_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;initializer_range&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">0.02</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;layer_norm_epsilon&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">1e-05</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;model_type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;gpt2&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;n_embd&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">768</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;n_head&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">12</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;n_inner&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">null</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;n_layer&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">12</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;n_positions&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1024</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;reorder_and_upcast_attn&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">false</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;resid_pdrop&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">0.1</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;scale_attn_by_inverse_layer_idx&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">false</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;scale_attn_weights&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;summary_activation&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;tanh&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;summary_first_dropout&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">0.1</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;summary_proj_to_labels&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;summary_type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;cls_index&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;summary_hidden_size&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">128</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;summary_use_proj&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;transformers_version&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;4.31.0&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;use_cache&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;vocab_size&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">10000</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;num_labels&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">9</span>
<span class="p">}</span>
</code></pre></div>
<h2 id="safe-model">SAFE Model<a class="headerlink" href="#safe-model" title="Permanent link">&para;</a></h2>


<div class="doc doc-object doc-module">



<a id="safe.trainer.model"></a>
  <div class="doc doc-contents first">

  

  <div class="doc doc-children">








<div class="doc doc-object doc-class">




<h2 id="safe.trainer.model.PropertyHead" class="doc doc-heading">
          <code>PropertyHead</code>


<a href="#safe.trainer.model.PropertyHead" class="headerlink" title="Permanent link">&para;</a></h2>


  <div class="doc doc-contents ">
          <p class="doc doc-class-bases">
            Bases: <code><span title="torch.nn.Module">Module</span></code></p>

  
      <p>Compute a single vector summary of a sequence hidden states.</p>



  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>config</code></td>
          <td>
                <code>[`PretrainedConfig`]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>The config used by the model. Relevant arguments in the config class of the model are (refer to the actual
config class of your model for the default values it uses):</p>
<ul>
<li><strong>summary_type</strong> (<code>str</code>) -- The method to use to make this summary. Accepted values are:<p>- <code>"last"</code> -- Take the last token hidden state (like XLNet)
  - <code>"first"</code> -- Take the first token hidden state (like Bert)
  - <code>"mean"</code> -- Take the mean of all tokens hidden states
  - <code>"cls_index"</code> -- Supply a Tensor of classification token position (GPT/GPT-2)</p>
</li>
</ul>
<ul>
<li><strong>summary_activation</strong> (<code>Optional[str]</code>) -- Set to <code>"tanh"</code> to add a tanh activation to the output,
  another string, or <code>None</code> to add no activation.</li>
</ul>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

            <details class="quote">
              <summary>Source code in <code>safe/trainer/model.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">PropertyHead</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute a single vector summary of a sequence hidden states.</span>

<span class="sd">    Args:</span>
<span class="sd">        config ([`PretrainedConfig`]):</span>
<span class="sd">            The config used by the model. Relevant arguments in the config class of the model are (refer to the actual</span>
<span class="sd">            config class of your model for the default values it uses):</span>

<span class="sd">            - **summary_type** (`str`) -- The method to use to make this summary. Accepted values are:</span>

<span class="sd">                - `&quot;last&quot;` -- Take the last token hidden state (like XLNet)</span>
<span class="sd">                - `&quot;first&quot;` -- Take the first token hidden state (like Bert)</span>
<span class="sd">                - `&quot;mean&quot;` -- Take the mean of all tokens hidden states</span>
<span class="sd">                - `&quot;cls_index&quot;` -- Supply a Tensor of classification token position (GPT/GPT-2)</span>

<span class="sd">            - **summary_activation** (`Optional[str]`) -- Set to `&quot;tanh&quot;` to add a tanh activation to the output,</span>
<span class="sd">              another string, or `None` to add no activation.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">:</span> <span class="n">PretrainedConfig</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">summary_type</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="s2">&quot;summary_type&quot;</span><span class="p">,</span> <span class="s2">&quot;cls_index&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">summary</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>
        <span class="n">last_hidden_size</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span>

        <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="s2">&quot;summary_hidden_size&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="n">config</span><span class="o">.</span><span class="n">summary_hidden_size</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">summary</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">summary_hidden_size</span><span class="p">)</span>
            <span class="n">last_hidden_size</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">summary_hidden_size</span>

        <span class="n">activation_string</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="s2">&quot;summary_activation&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">get_activation</span><span class="p">(</span><span class="n">activation_string</span><span class="p">)</span> <span class="k">if</span> <span class="n">activation_string</span> <span class="k">else</span> <span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="s2">&quot;num_labels&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="n">config</span><span class="o">.</span><span class="n">num_labels</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">num_labels</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">num_labels</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">out</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">last_hidden_size</span><span class="p">,</span> <span class="n">num_labels</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">hidden_states</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">,</span>
        <span class="n">cls_index</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute a single vector summary of a sequence hidden states.</span>

<span class="sd">        Args:</span>
<span class="sd">            hidden_states: `torch.FloatTensor` of shape `[batch_size, seq_len, hidden_size]`)</span>
<span class="sd">                The hidden states of the last layer.</span>
<span class="sd">            cls_index: `torch.LongTensor` of shape `[batch_size]` or `[batch_size, ...]`</span>
<span class="sd">                where ... are optional leading dimensions of `hidden_states`, *optional*</span>
<span class="sd">                Used if `summary_type == &quot;cls_index&quot;` and takes the last token of the sequence as classification token.</span>

<span class="sd">        Returns:</span>
<span class="sd">            `torch.FloatTensor`: The summary of the sequence hidden states.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">summary_type</span> <span class="o">==</span> <span class="s2">&quot;last&quot;</span><span class="p">:</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">hidden_states</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">summary_type</span> <span class="o">==</span> <span class="s2">&quot;first&quot;</span><span class="p">:</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">hidden_states</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">summary_type</span> <span class="o">==</span> <span class="s2">&quot;mean&quot;</span><span class="p">:</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">hidden_states</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">summary_type</span> <span class="o">==</span> <span class="s2">&quot;cls_index&quot;</span><span class="p">:</span>
            <span class="c1"># if cls_index is None:</span>
            <span class="c1">#     cls_index = torch.full_like(</span>
            <span class="c1">#         hidden_states[..., :1, :],</span>
            <span class="c1">#         hidden_states.shape[-2] - 1,</span>
            <span class="c1">#         dtype=torch.long,</span>
            <span class="c1">#     )</span>
            <span class="c1"># else:</span>
            <span class="c1">#     cls_index = cls_index.unsqueeze(-1).unsqueeze(-1)</span>
            <span class="c1">#     cls_index = cls_index.expand(</span>
            <span class="c1">#         (-1,) * (cls_index.dim() - 1) + (hidden_states.size(-1),)</span>
            <span class="c1">#     )</span>

            <span class="c1"># shape of cls_index: (bsz, XX, 1, hidden_size) where XX are optional leading dim of hidden_states</span>
            <span class="c1"># output = hidden_states.gather(-2, cls_index).squeeze(-2)  # shape (bsz, XX, hidden_size)</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="n">hidden_states</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">hidden_states</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()[</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">batch_size</span><span class="p">),</span> <span class="n">cls_index</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span>

        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">out</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">




<h3 id="safe.trainer.model.PropertyHead.forward" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">,</span> <span class="n">cls_index</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#safe.trainer.model.PropertyHead.forward" class="headerlink" title="Permanent link">&para;</a></h3>


  <div class="doc doc-contents ">
  
      <p>Compute a single vector summary of a sequence hidden states.</p>



  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>hidden_states</code></td>
          <td>
                <code><span title="torch.FloatTensor">FloatTensor</span></code>
          </td>
          <td>
            <div class="doc-md-description">
              <p><code>torch.FloatTensor</code> of shape <code>[batch_size, seq_len, hidden_size]</code>)
The hidden states of the last layer.</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>cls_index</code></td>
          <td>
                <code><a class="autorefs autorefs-external" title="typing.Optional" href="https://docs.python.org/3/library/typing.html#typing.Optional">Optional</a>[<span title="torch.LongTensor">LongTensor</span>]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p><code>torch.LongTensor</code> of shape <code>[batch_size]</code> or <code>[batch_size, ...]</code>
where ... are optional leading dimensions of <code>hidden_states</code>, <em>optional</em>
Used if <code>summary_type == "cls_index"</code> and takes the last token of the sequence as classification token.</p>
            </div>
          </td>
          <td>
                <code>None</code>
          </td>
        </tr>
    </tbody>
  </table>



  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code><span title="torch.FloatTensor">FloatTensor</span></code>
          </td>
          <td>
            <div class="doc-md-description">
              <p><code>torch.FloatTensor</code>: The summary of the sequence hidden states.</p>
            </div>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>safe/trainer/model.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">hidden_states</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">,</span>
    <span class="n">cls_index</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute a single vector summary of a sequence hidden states.</span>

<span class="sd">    Args:</span>
<span class="sd">        hidden_states: `torch.FloatTensor` of shape `[batch_size, seq_len, hidden_size]`)</span>
<span class="sd">            The hidden states of the last layer.</span>
<span class="sd">        cls_index: `torch.LongTensor` of shape `[batch_size]` or `[batch_size, ...]`</span>
<span class="sd">            where ... are optional leading dimensions of `hidden_states`, *optional*</span>
<span class="sd">            Used if `summary_type == &quot;cls_index&quot;` and takes the last token of the sequence as classification token.</span>

<span class="sd">    Returns:</span>
<span class="sd">        `torch.FloatTensor`: The summary of the sequence hidden states.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">summary_type</span> <span class="o">==</span> <span class="s2">&quot;last&quot;</span><span class="p">:</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">hidden_states</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">summary_type</span> <span class="o">==</span> <span class="s2">&quot;first&quot;</span><span class="p">:</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">hidden_states</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">summary_type</span> <span class="o">==</span> <span class="s2">&quot;mean&quot;</span><span class="p">:</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">hidden_states</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">summary_type</span> <span class="o">==</span> <span class="s2">&quot;cls_index&quot;</span><span class="p">:</span>
        <span class="c1"># if cls_index is None:</span>
        <span class="c1">#     cls_index = torch.full_like(</span>
        <span class="c1">#         hidden_states[..., :1, :],</span>
        <span class="c1">#         hidden_states.shape[-2] - 1,</span>
        <span class="c1">#         dtype=torch.long,</span>
        <span class="c1">#     )</span>
        <span class="c1"># else:</span>
        <span class="c1">#     cls_index = cls_index.unsqueeze(-1).unsqueeze(-1)</span>
        <span class="c1">#     cls_index = cls_index.expand(</span>
        <span class="c1">#         (-1,) * (cls_index.dim() - 1) + (hidden_states.size(-1),)</span>
        <span class="c1">#     )</span>

        <span class="c1"># shape of cls_index: (bsz, XX, 1, hidden_size) where XX are optional leading dim of hidden_states</span>
        <span class="c1"># output = hidden_states.gather(-2, cls_index).squeeze(-2)  # shape (bsz, XX, hidden_size)</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">hidden_states</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">hidden_states</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()[</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">batch_size</span><span class="p">),</span> <span class="n">cls_index</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">out</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>

</div>

<div class="doc doc-object doc-class">




<h2 id="safe.trainer.model.SAFEDoubleHeadsModel" class="doc doc-heading">
          <code>SAFEDoubleHeadsModel</code>


<a href="#safe.trainer.model.SAFEDoubleHeadsModel" class="headerlink" title="Permanent link">&para;</a></h2>


  <div class="doc doc-contents ">
          <p class="doc doc-class-bases">
            Bases: <code><span title="transformers.GPT2DoubleHeadsModel">GPT2DoubleHeadsModel</span></code></p>

  
      <p>The safe model is a dual head GPT2 model with a language modeling head and an optional multi-task regression head</p>

            <details class="quote">
              <summary>Source code in <code>safe/trainer/model.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">SAFEDoubleHeadsModel</span><span class="p">(</span><span class="n">GPT2DoubleHeadsModel</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;The safe model is a dual head GPT2 model with a language modeling head and an optional multi-task regression head&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="s2">&quot;num_labels&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">num_labels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_labels</span>
        <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">multiple_choice_head</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">multiple_choice_head</span> <span class="o">=</span> <span class="n">PropertyHead</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>

    <span class="nd">@add_start_docstrings_to_model_forward</span><span class="p">(</span><span class="n">GPT2_INPUTS_DOCSTRING</span><span class="p">)</span>
    <span class="nd">@replace_return_docstrings</span><span class="p">(</span><span class="n">output_type</span><span class="o">=</span><span class="n">GPT2DoubleHeadsModelOutput</span><span class="p">,</span> <span class="n">config_class</span><span class="o">=</span><span class="n">_CONFIG_FOR_DOC</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">input_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">past_key_values</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">attention_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">token_type_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">position_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">head_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">inputs_embeds</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">mc_token_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">mc_labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">use_cache</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_attentions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_hidden_states</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">return_dict</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">inputs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># do not remove because of trainer</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tuple</span><span class="p">,</span> <span class="n">GPT2DoubleHeadsModelOutput</span><span class="p">]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Args:</span>
<span class="sd">            mc_token_ids (`torch.LongTensor` of shape `(batch_size, num_choices)`, *optional*, default to index of the last token of the input):</span>
<span class="sd">                Index of the classification token in each input sequence. Selected in the range `[0, input_ids.size(-1) -</span>
<span class="sd">                1]`.</span>
<span class="sd">            labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):</span>
<span class="sd">                Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set</span>
<span class="sd">                `labels = input_ids`. Indices are selected in `[-100, 0, ..., config.vocab_size - 1]`. All labels set to</span>
<span class="sd">                `-100` are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size - 1]`</span>
<span class="sd">            mc_labels (`torch.LongTensor` of shape `(batch_size, n_tasks)`, *optional*):</span>
<span class="sd">                Labels for computing the supervized loss for regularization.</span>
<span class="sd">            inputs: List of inputs, put here because the trainer removes information not in signature</span>
<span class="sd">        Returns:</span>
<span class="sd">            output (GPT2DoubleHeadsModelOutput): output of the model</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">return_dict</span> <span class="o">=</span> <span class="n">return_dict</span> <span class="k">if</span> <span class="n">return_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">use_return_dict</span>
        <span class="n">transformer_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer</span><span class="p">(</span>
            <span class="n">input_ids</span><span class="p">,</span>
            <span class="n">past_key_values</span><span class="o">=</span><span class="n">past_key_values</span><span class="p">,</span>
            <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span>
            <span class="n">token_type_ids</span><span class="o">=</span><span class="n">token_type_ids</span><span class="p">,</span>
            <span class="n">position_ids</span><span class="o">=</span><span class="n">position_ids</span><span class="p">,</span>
            <span class="n">head_mask</span><span class="o">=</span><span class="n">head_mask</span><span class="p">,</span>
            <span class="n">inputs_embeds</span><span class="o">=</span><span class="n">inputs_embeds</span><span class="p">,</span>
            <span class="n">use_cache</span><span class="o">=</span><span class="n">use_cache</span><span class="p">,</span>
            <span class="n">output_attentions</span><span class="o">=</span><span class="n">output_attentions</span><span class="p">,</span>
            <span class="n">output_hidden_states</span><span class="o">=</span><span class="n">output_hidden_states</span><span class="p">,</span>
            <span class="n">return_dict</span><span class="o">=</span><span class="n">return_dict</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">transformer_outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">lm_logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm_head</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">mc_token_ids</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">input_ids</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">mc_token_ids</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ne</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pad_token_id</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span>
                <span class="n">lm_logits</span><span class="o">.</span><span class="n">device</span>
            <span class="p">)</span>

        <span class="c1"># Set device for model parallelism</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_parallel</span><span class="p">:</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">set_device</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">first_device</span><span class="p">)</span>
            <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">hidden_states</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lm_head</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="n">mc_loss</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">mc_logits</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">mc_labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s2">&quot;num_labels&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">mc_logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">multiple_choice_head</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">,</span> <span class="n">mc_token_ids</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">mc_labels</span> <span class="o">=</span> <span class="n">mc_labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">mc_logits</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">MSELoss</span><span class="p">()</span>
            <span class="n">mc_loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span>
                <span class="n">mc_logits</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">mc_logits</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)),</span> <span class="n">mc_labels</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">mc_logits</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
            <span class="p">)</span>

        <span class="n">lm_loss</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">lm_logits</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">shift_logits</span> <span class="o">=</span> <span class="n">lm_logits</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
            <span class="n">shift_labels</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
            <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">CrossEntropyLoss</span><span class="p">()</span>
            <span class="n">lm_loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">shift_logits</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">shift_logits</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)),</span> <span class="n">shift_labels</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">return_dict</span><span class="p">:</span>
            <span class="n">output</span> <span class="o">=</span> <span class="p">(</span><span class="n">lm_logits</span><span class="p">,</span> <span class="n">mc_logits</span><span class="p">)</span> <span class="o">+</span> <span class="n">transformer_outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
            <span class="k">return</span> <span class="p">(</span>
                <span class="n">lm_loss</span><span class="p">,</span>
                <span class="n">mc_loss</span><span class="p">,</span>
            <span class="p">)</span> <span class="o">+</span> <span class="n">output</span>

        <span class="k">return</span> <span class="n">GPT2DoubleHeadsModelOutput</span><span class="p">(</span>
            <span class="n">loss</span><span class="o">=</span><span class="n">lm_loss</span><span class="p">,</span>
            <span class="n">mc_loss</span><span class="o">=</span><span class="n">mc_loss</span><span class="p">,</span>
            <span class="n">logits</span><span class="o">=</span><span class="n">lm_logits</span><span class="p">,</span>
            <span class="n">mc_logits</span><span class="o">=</span><span class="n">mc_logits</span><span class="p">,</span>
            <span class="n">past_key_values</span><span class="o">=</span><span class="n">transformer_outputs</span><span class="o">.</span><span class="n">past_key_values</span><span class="p">,</span>
            <span class="n">hidden_states</span><span class="o">=</span><span class="n">transformer_outputs</span><span class="o">.</span><span class="n">hidden_states</span><span class="p">,</span>
            <span class="n">attentions</span><span class="o">=</span><span class="n">transformer_outputs</span><span class="o">.</span><span class="n">attentions</span><span class="p">,</span>
        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">




<h3 id="safe.trainer.model.SAFEDoubleHeadsModel.forward" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">input_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">past_key_values</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">token_type_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">position_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">head_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">inputs_embeds</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mc_token_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mc_labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">use_cache</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_attentions</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_hidden_states</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#safe.trainer.model.SAFEDoubleHeadsModel.forward" class="headerlink" title="Permanent link">&para;</a></h3>


  <div class="doc doc-contents ">
  



  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>mc_token_ids</code></td>
          <td>
                <code>`torch.LongTensor` of shape `(batch_size, num_choices)`, *optional*, default to index of the last token of the input</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Index of the classification token in each input sequence. Selected in the range <code>[0, input_ids.size(-1) -
1]</code>.</p>
            </div>
          </td>
          <td>
                <code>None</code>
          </td>
        </tr>
        <tr>
          <td><code>labels</code></td>
          <td>
                <code>`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Labels for language modeling. Note that the labels <strong>are shifted</strong> inside the model, i.e. you can set
<code>labels = input_ids</code>. Indices are selected in <code>[-100, 0, ..., config.vocab_size - 1]</code>. All labels set to
<code>-100</code> are ignored (masked), the loss is only computed for labels in <code>[0, ..., config.vocab_size - 1]</code></p>
            </div>
          </td>
          <td>
                <code>None</code>
          </td>
        </tr>
        <tr>
          <td><code>mc_labels</code></td>
          <td>
                <code>`torch.LongTensor` of shape `(batch_size, n_tasks)`, *optional*</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Labels for computing the supervized loss for regularization.</p>
            </div>
          </td>
          <td>
                <code>None</code>
          </td>
        </tr>
        <tr>
          <td><code>inputs</code></td>
          <td>
                <code><a class="autorefs autorefs-external" title="typing.Optional" href="https://docs.python.org/3/library/typing.html#typing.Optional">Optional</a>[<a class="autorefs autorefs-external" title="typing.Any" href="https://docs.python.org/3/library/typing.html#typing.Any">Any</a>]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>List of inputs, put here because the trainer removes information not in signature</p>
            </div>
          </td>
          <td>
                <code>None</code>
          </td>
        </tr>
    </tbody>
  </table>
      <p>Returns:
    output (GPT2DoubleHeadsModelOutput): output of the model</p>

          <details class="quote">
            <summary>Source code in <code>safe/trainer/model.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@add_start_docstrings_to_model_forward</span><span class="p">(</span><span class="n">GPT2_INPUTS_DOCSTRING</span><span class="p">)</span>
<span class="nd">@replace_return_docstrings</span><span class="p">(</span><span class="n">output_type</span><span class="o">=</span><span class="n">GPT2DoubleHeadsModelOutput</span><span class="p">,</span> <span class="n">config_class</span><span class="o">=</span><span class="n">_CONFIG_FOR_DOC</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">input_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">past_key_values</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">attention_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">token_type_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">position_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">head_mask</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">inputs_embeds</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">mc_token_ids</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">mc_labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">use_cache</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">output_attentions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">output_hidden_states</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">return_dict</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">inputs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>  <span class="c1"># do not remove because of trainer</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tuple</span><span class="p">,</span> <span class="n">GPT2DoubleHeadsModelOutput</span><span class="p">]:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">    Args:</span>
<span class="sd">        mc_token_ids (`torch.LongTensor` of shape `(batch_size, num_choices)`, *optional*, default to index of the last token of the input):</span>
<span class="sd">            Index of the classification token in each input sequence. Selected in the range `[0, input_ids.size(-1) -</span>
<span class="sd">            1]`.</span>
<span class="sd">        labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):</span>
<span class="sd">            Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set</span>
<span class="sd">            `labels = input_ids`. Indices are selected in `[-100, 0, ..., config.vocab_size - 1]`. All labels set to</span>
<span class="sd">            `-100` are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size - 1]`</span>
<span class="sd">        mc_labels (`torch.LongTensor` of shape `(batch_size, n_tasks)`, *optional*):</span>
<span class="sd">            Labels for computing the supervized loss for regularization.</span>
<span class="sd">        inputs: List of inputs, put here because the trainer removes information not in signature</span>
<span class="sd">    Returns:</span>
<span class="sd">        output (GPT2DoubleHeadsModelOutput): output of the model</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">return_dict</span> <span class="o">=</span> <span class="n">return_dict</span> <span class="k">if</span> <span class="n">return_dict</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">use_return_dict</span>
    <span class="n">transformer_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer</span><span class="p">(</span>
        <span class="n">input_ids</span><span class="p">,</span>
        <span class="n">past_key_values</span><span class="o">=</span><span class="n">past_key_values</span><span class="p">,</span>
        <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span>
        <span class="n">token_type_ids</span><span class="o">=</span><span class="n">token_type_ids</span><span class="p">,</span>
        <span class="n">position_ids</span><span class="o">=</span><span class="n">position_ids</span><span class="p">,</span>
        <span class="n">head_mask</span><span class="o">=</span><span class="n">head_mask</span><span class="p">,</span>
        <span class="n">inputs_embeds</span><span class="o">=</span><span class="n">inputs_embeds</span><span class="p">,</span>
        <span class="n">use_cache</span><span class="o">=</span><span class="n">use_cache</span><span class="p">,</span>
        <span class="n">output_attentions</span><span class="o">=</span><span class="n">output_attentions</span><span class="p">,</span>
        <span class="n">output_hidden_states</span><span class="o">=</span><span class="n">output_hidden_states</span><span class="p">,</span>
        <span class="n">return_dict</span><span class="o">=</span><span class="n">return_dict</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">transformer_outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">lm_logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm_head</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">mc_token_ids</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">input_ids</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">mc_token_ids</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ne</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pad_token_id</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span>
            <span class="n">lm_logits</span><span class="o">.</span><span class="n">device</span>
        <span class="p">)</span>

    <span class="c1"># Set device for model parallelism</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_parallel</span><span class="p">:</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">set_device</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">first_device</span><span class="p">)</span>
        <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">hidden_states</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lm_head</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="n">mc_loss</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">mc_logits</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">mc_labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s2">&quot;num_labels&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">mc_logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">multiple_choice_head</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">,</span> <span class="n">mc_token_ids</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">mc_labels</span> <span class="o">=</span> <span class="n">mc_labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">mc_logits</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">MSELoss</span><span class="p">()</span>
        <span class="n">mc_loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span>
            <span class="n">mc_logits</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">mc_logits</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)),</span> <span class="n">mc_labels</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">mc_logits</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="p">)</span>

    <span class="n">lm_loss</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">lm_logits</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="n">shift_logits</span> <span class="o">=</span> <span class="n">lm_logits</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
        <span class="n">shift_labels</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
        <span class="n">loss_fct</span> <span class="o">=</span> <span class="n">CrossEntropyLoss</span><span class="p">()</span>
        <span class="n">lm_loss</span> <span class="o">=</span> <span class="n">loss_fct</span><span class="p">(</span><span class="n">shift_logits</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">shift_logits</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)),</span> <span class="n">shift_labels</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">return_dict</span><span class="p">:</span>
        <span class="n">output</span> <span class="o">=</span> <span class="p">(</span><span class="n">lm_logits</span><span class="p">,</span> <span class="n">mc_logits</span><span class="p">)</span> <span class="o">+</span> <span class="n">transformer_outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="n">lm_loss</span><span class="p">,</span>
            <span class="n">mc_loss</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">+</span> <span class="n">output</span>

    <span class="k">return</span> <span class="n">GPT2DoubleHeadsModelOutput</span><span class="p">(</span>
        <span class="n">loss</span><span class="o">=</span><span class="n">lm_loss</span><span class="p">,</span>
        <span class="n">mc_loss</span><span class="o">=</span><span class="n">mc_loss</span><span class="p">,</span>
        <span class="n">logits</span><span class="o">=</span><span class="n">lm_logits</span><span class="p">,</span>
        <span class="n">mc_logits</span><span class="o">=</span><span class="n">mc_logits</span><span class="p">,</span>
        <span class="n">past_key_values</span><span class="o">=</span><span class="n">transformer_outputs</span><span class="o">.</span><span class="n">past_key_values</span><span class="p">,</span>
        <span class="n">hidden_states</span><span class="o">=</span><span class="n">transformer_outputs</span><span class="o">.</span><span class="n">hidden_states</span><span class="p">,</span>
        <span class="n">attentions</span><span class="o">=</span><span class="n">transformer_outputs</span><span class="o">.</span><span class="n">attentions</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>

</div>




  </div>

  </div>

</div><hr />
<h2 id="trainer">Trainer<a class="headerlink" href="#trainer" title="Permanent link">&para;</a></h2>


<div class="doc doc-object doc-module">



<a id="safe.trainer.trainer_utils"></a>
  <div class="doc doc-contents first">

  

  <div class="doc doc-children">








<div class="doc doc-object doc-class">




<h2 id="safe.trainer.trainer_utils.SAFETrainer" class="doc doc-heading">
          <code>SAFETrainer</code>


<a href="#safe.trainer.trainer_utils.SAFETrainer" class="headerlink" title="Permanent link">&para;</a></h2>


  <div class="doc doc-contents ">
          <p class="doc doc-class-bases">
            Bases: <code><span title="transformers.Trainer">Trainer</span></code></p>

  
      <p>Custom trainer for training SAFE model.</p>
<p>This custom trainer changes the loss function to support the property head</p>

            <details class="quote">
              <summary>Source code in <code>safe/trainer/trainer_utils.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">SAFETrainer</span><span class="p">(</span><span class="n">Trainer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Custom trainer for training SAFE model.</span>

<span class="sd">    This custom trainer changes the loss function to support the property head</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="n">prop_loss_coeff</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-3</span><span class="p">,</span> <span class="n">dispatch_batches</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prop_loss_coeff</span> <span class="o">=</span> <span class="n">prop_loss_coeff</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">accelerator</span><span class="o">.</span><span class="n">dispatch_batches</span> <span class="o">=</span> <span class="n">dispatch_batches</span>

    <span class="k">def</span> <span class="nf">compute_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">return_outputs</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        How the loss is computed by Trainer. By default, all models return the loss in the first element.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">inputs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;labels&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">label_smoother</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="s2">&quot;labels&quot;</span> <span class="ow">in</span> <span class="n">inputs</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="p">)</span>

        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span>
        <span class="c1"># Save past state if it exists</span>
        <span class="c1"># TODO: this needs to be fixed and made cleaner later.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">past_index</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_past</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">past_index</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">unwrap_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span><span class="o">.</span><span class="n">_get_name</span><span class="p">()</span> <span class="ow">in</span> <span class="n">MODEL_FOR_CAUSAL_LM_MAPPING_NAMES</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">label_smoother</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">shift_labels</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">label_smoother</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="ow">and</span> <span class="s2">&quot;loss&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;The model did not return a loss from the inputs, only the following keys: &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="s1">&#39;,&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s2">. For reference, the inputs it received are </span><span class="si">{</span><span class="s1">&#39;,&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="p">)</span>
            <span class="c1"># We don&#39;t use .loss here since the model may return tuples instead of ModelOutput.</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">]</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="k">else</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">mc_loss</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;mc_loss&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="k">else</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">mc_loss</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">prop_loss_coeff</span> <span class="o">*</span> <span class="n">mc_loss</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span> <span class="k">if</span> <span class="n">return_outputs</span> <span class="k">else</span> <span class="n">loss</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">




<h3 id="safe.trainer.trainer_utils.SAFETrainer.compute_loss" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">compute_loss</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">return_outputs</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

<a href="#safe.trainer.trainer_utils.SAFETrainer.compute_loss" class="headerlink" title="Permanent link">&para;</a></h3>


  <div class="doc doc-contents ">
  
      <p>How the loss is computed by Trainer. By default, all models return the loss in the first element.</p>

          <details class="quote">
            <summary>Source code in <code>safe/trainer/trainer_utils.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">compute_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">return_outputs</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    How the loss is computed by Trainer. By default, all models return the loss in the first element.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">inputs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;labels&quot;</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">label_smoother</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="s2">&quot;labels&quot;</span> <span class="ow">in</span> <span class="n">inputs</span> <span class="k">else</span> <span class="kc">None</span>
    <span class="p">)</span>

    <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span>
    <span class="c1"># Save past state if it exists</span>
    <span class="c1"># TODO: this needs to be fixed and made cleaner later.</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">past_index</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_past</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">past_index</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">unwrap_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span><span class="o">.</span><span class="n">_get_name</span><span class="p">()</span> <span class="ow">in</span> <span class="n">MODEL_FOR_CAUSAL_LM_MAPPING_NAMES</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">label_smoother</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">shift_labels</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">label_smoother</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="ow">and</span> <span class="s2">&quot;loss&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;The model did not return a loss from the inputs, only the following keys: &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="s1">&#39;,&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s2">. For reference, the inputs it received are </span><span class="si">{</span><span class="s1">&#39;,&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>
        <span class="c1"># We don&#39;t use .loss here since the model may return tuples instead of ModelOutput.</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">]</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="k">else</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">mc_loss</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;mc_loss&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="k">else</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">mc_loss</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">prop_loss_coeff</span> <span class="o">*</span> <span class="n">mc_loss</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span> <span class="k">if</span> <span class="n">return_outputs</span> <span class="k">else</span> <span class="n">loss</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>

</div>




  </div>

  </div>

</div><hr />
<h2 id="data-collator">Data Collator<a class="headerlink" href="#data-collator" title="Permanent link">&para;</a></h2>


<div class="doc doc-object doc-module">



<a id="safe.trainer.collator"></a>
  <div class="doc doc-contents first">

  

  <div class="doc doc-children">








<div class="doc doc-object doc-class">




<h2 id="safe.trainer.collator.SAFECollator" class="doc doc-heading">
          <code>SAFECollator</code>


<a href="#safe.trainer.collator.SAFECollator" class="headerlink" title="Permanent link">&para;</a></h2>


  <div class="doc doc-contents ">

  
      <p>Collate function for language modelling tasks</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The collate function is based on the default DataCollatorForLanguageModeling in huggingface
see: <a href="https://github.com/huggingface/transformers/blob/v4.19.2/src/transformers/data/data_collator.py">https://github.com/huggingface/transformers/blob/v4.19.2/src/transformers/data/data_collator.py</a></p>
</div>

            <details class="quote">
              <summary>Source code in <code>safe/trainer/collator.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 18</span>
<span class="normal"> 19</span>
<span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">SAFECollator</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Collate function for language modelling tasks</span>


<span class="sd">    !!! note</span>
<span class="sd">        The collate function is based on the default DataCollatorForLanguageModeling in huggingface</span>
<span class="sd">        see: https://github.com/huggingface/transformers/blob/v4.19.2/src/transformers/data/data_collator.py</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="p">:</span> <span class="n">Tokenizer</span><span class="p">,</span>
        <span class="n">pad_to_multiple_of</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">input_key</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;inputs&quot;</span><span class="p">,</span>
        <span class="n">label_key</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;labels&quot;</span><span class="p">,</span>
        <span class="n">property_key</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;descriptors&quot;</span><span class="p">,</span>
        <span class="n">include_descriptors</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">max_length</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Default collator for huggingface transformers in izanagi.</span>

<span class="sd">        Args:</span>
<span class="sd">            tokenizer: Huggingface tokenizer</span>
<span class="sd">            input_key: key to use for input ids</span>
<span class="sd">            label_key: key to use for labels</span>
<span class="sd">            property_key: key to use for properties</span>
<span class="sd">            include_descriptors: whether to include training on descriptors or not</span>
<span class="sd">            pad_to_multiple_of: pad to multiple of this value</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tokenizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pad_to_multiple_of</span> <span class="o">=</span> <span class="n">pad_to_multiple_of</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_key</span> <span class="o">=</span> <span class="n">input_key</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">label_key</span> <span class="o">=</span> <span class="n">label_key</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">property_key</span> <span class="o">=</span> <span class="n">property_key</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">include_descriptors</span> <span class="o">=</span> <span class="n">include_descriptors</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_length</span> <span class="o">=</span> <span class="n">max_length</span>

    <span class="nd">@functools</span><span class="o">.</span><span class="n">lru_cache</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">get_tokenizer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get underlying tokenizer&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">SAFETokenizer</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">get_pretrained</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">samples</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]]):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Call collate function</span>

<span class="sd">        Args:</span>
<span class="sd">            samples: list of examples</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Handle dict or lists with proper padding and conversion to tensor.</span>
        <span class="n">tokenizer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_tokenizer</span><span class="p">()</span>

        <span class="c1"># examples = samples</span>
        <span class="n">examples</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">example</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_key</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">examples</span><span class="p">]</span>
        <span class="n">mc_labels</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">example</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">property_key</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">examples</span><span class="p">])</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">property_key</span> <span class="ow">in</span> <span class="n">examples</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">else</span> <span class="kc">None</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="s2">&quot;input_ids&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">examples</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">and</span> <span class="n">inputs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">batch</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
                <span class="n">inputs</span><span class="p">,</span>
                <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span>
                <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">max_length</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_length</span><span class="p">,</span>
                <span class="n">pad_to_multiple_of</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">pad_to_multiple_of</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">batch</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span>
                <span class="n">examples</span><span class="p">,</span>
                <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span>
                <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">pad_to_multiple_of</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">pad_to_multiple_of</span><span class="p">,</span>
                <span class="n">max_length</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_length</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="c1"># If special token mask has been preprocessed, pop it from the dict.</span>
        <span class="n">batch</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;special_tokens_mask&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;labels&quot;</span><span class="p">,</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">())</span>
        <span class="k">if</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">labels</span><span class="p">[</span><span class="n">labels</span> <span class="o">==</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">100</span>
        <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;labels&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">labels</span>

        <span class="k">if</span> <span class="n">mc_labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">include_descriptors</span><span class="p">:</span>
            <span class="n">batch</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                <span class="p">{</span>
                    <span class="s2">&quot;mc_labels&quot;</span><span class="p">:</span> <span class="n">mc_labels</span><span class="p">,</span>
                    <span class="c1"># &quot;input_text&quot;: inputs,</span>
                <span class="p">}</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">batch</span>
</code></pre></div></td></tr></table></div>
            </details>

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">




<h3 id="safe.trainer.collator.SAFECollator.__call__" class="doc doc-heading">
          <code class="highlight language-python"><span class="fm">__call__</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span></code>

<a href="#safe.trainer.collator.SAFECollator.__call__" class="headerlink" title="Permanent link">&para;</a></h3>


  <div class="doc doc-contents ">
  
      <p>Call collate function</p>



  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>samples</code></td>
          <td>
                <code><a class="autorefs autorefs-external" title="typing.List" href="https://docs.python.org/3/library/typing.html#typing.List">List</a>[<a class="autorefs autorefs-external" title="typing.Union" href="https://docs.python.org/3/library/typing.html#typing.Union">Union</a>[<a class="autorefs autorefs-external" title="typing.List" href="https://docs.python.org/3/library/typing.html#typing.List">List</a>[<a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a>], <a class="autorefs autorefs-external" title="typing.Any" href="https://docs.python.org/3/library/typing.html#typing.Any">Any</a>, <a class="autorefs autorefs-external" title="typing.Dict" href="https://docs.python.org/3/library/typing.html#typing.Dict">Dict</a>[<a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a>, <a class="autorefs autorefs-external" title="typing.Any" href="https://docs.python.org/3/library/typing.html#typing.Any">Any</a>]]]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>list of examples</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>safe/trainer/collator.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">samples</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]]):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Call collate function</span>

<span class="sd">    Args:</span>
<span class="sd">        samples: list of examples</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Handle dict or lists with proper padding and conversion to tensor.</span>
    <span class="n">tokenizer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_tokenizer</span><span class="p">()</span>

    <span class="c1"># examples = samples</span>
    <span class="n">examples</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">example</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_key</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">examples</span><span class="p">]</span>
    <span class="n">mc_labels</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">example</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">property_key</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">examples</span><span class="p">])</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">property_key</span> <span class="ow">in</span> <span class="n">examples</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span> <span class="kc">None</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="s2">&quot;input_ids&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">examples</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">and</span> <span class="n">inputs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
            <span class="n">inputs</span><span class="p">,</span>
            <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span>
            <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">max_length</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_length</span><span class="p">,</span>
            <span class="n">pad_to_multiple_of</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">pad_to_multiple_of</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span>
            <span class="n">examples</span><span class="p">,</span>
            <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span>
            <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">pad_to_multiple_of</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">pad_to_multiple_of</span><span class="p">,</span>
            <span class="n">max_length</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_length</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="c1"># If special token mask has been preprocessed, pop it from the dict.</span>
    <span class="n">batch</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;special_tokens_mask&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;labels&quot;</span><span class="p">,</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">clone</span><span class="p">())</span>
    <span class="k">if</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">labels</span><span class="p">[</span><span class="n">labels</span> <span class="o">==</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">100</span>
    <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;labels&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">labels</span>

    <span class="k">if</span> <span class="n">mc_labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">include_descriptors</span><span class="p">:</span>
        <span class="n">batch</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
            <span class="p">{</span>
                <span class="s2">&quot;mc_labels&quot;</span><span class="p">:</span> <span class="n">mc_labels</span><span class="p">,</span>
                <span class="c1"># &quot;input_text&quot;: inputs,</span>
            <span class="p">}</span>
        <span class="p">)</span>
    <span class="k">return</span> <span class="n">batch</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">




<h3 id="safe.trainer.collator.SAFECollator.__init__" class="doc doc-heading">
          <code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">pad_to_multiple_of</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_key</span><span class="o">=</span><span class="s1">&#39;inputs&#39;</span><span class="p">,</span> <span class="n">label_key</span><span class="o">=</span><span class="s1">&#39;labels&#39;</span><span class="p">,</span> <span class="n">property_key</span><span class="o">=</span><span class="s1">&#39;descriptors&#39;</span><span class="p">,</span> <span class="n">include_descriptors</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#safe.trainer.collator.SAFECollator.__init__" class="headerlink" title="Permanent link">&para;</a></h3>


  <div class="doc doc-contents ">
  
      <p>Default collator for huggingface transformers in izanagi.</p>



  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>tokenizer</code></td>
          <td>
                <code><span title="tokenizers.Tokenizer">Tokenizer</span></code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Huggingface tokenizer</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>input_key</code></td>
          <td>
                <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>key to use for input ids</p>
            </div>
          </td>
          <td>
                <code>&#39;inputs&#39;</code>
          </td>
        </tr>
        <tr>
          <td><code>label_key</code></td>
          <td>
                <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>key to use for labels</p>
            </div>
          </td>
          <td>
                <code>&#39;labels&#39;</code>
          </td>
        </tr>
        <tr>
          <td><code>property_key</code></td>
          <td>
                <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a></code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>key to use for properties</p>
            </div>
          </td>
          <td>
                <code>&#39;descriptors&#39;</code>
          </td>
        </tr>
        <tr>
          <td><code>include_descriptors</code></td>
          <td>
                <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>whether to include training on descriptors or not</p>
            </div>
          </td>
          <td>
                <code>False</code>
          </td>
        </tr>
        <tr>
          <td><code>pad_to_multiple_of</code></td>
          <td>
                <code><a class="autorefs autorefs-external" title="typing.Optional" href="https://docs.python.org/3/library/typing.html#typing.Optional">Optional</a>[<a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a>]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>pad to multiple of this value</p>
            </div>
          </td>
          <td>
                <code>None</code>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>safe/trainer/collator.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">:</span> <span class="n">Tokenizer</span><span class="p">,</span>
    <span class="n">pad_to_multiple_of</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">input_key</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;inputs&quot;</span><span class="p">,</span>
    <span class="n">label_key</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;labels&quot;</span><span class="p">,</span>
    <span class="n">property_key</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;descriptors&quot;</span><span class="p">,</span>
    <span class="n">include_descriptors</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">max_length</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Default collator for huggingface transformers in izanagi.</span>

<span class="sd">    Args:</span>
<span class="sd">        tokenizer: Huggingface tokenizer</span>
<span class="sd">        input_key: key to use for input ids</span>
<span class="sd">        label_key: key to use for labels</span>
<span class="sd">        property_key: key to use for properties</span>
<span class="sd">        include_descriptors: whether to include training on descriptors or not</span>
<span class="sd">        pad_to_multiple_of: pad to multiple of this value</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tokenizer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pad_to_multiple_of</span> <span class="o">=</span> <span class="n">pad_to_multiple_of</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">input_key</span> <span class="o">=</span> <span class="n">input_key</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">label_key</span> <span class="o">=</span> <span class="n">label_key</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">property_key</span> <span class="o">=</span> <span class="n">property_key</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">include_descriptors</span> <span class="o">=</span> <span class="n">include_descriptors</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">max_length</span> <span class="o">=</span> <span class="n">max_length</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">




<h3 id="safe.trainer.collator.SAFECollator.get_tokenizer" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">get_tokenizer</span><span class="p">()</span></code>
  
  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-cached"><code>cached</code></small>
  </span>

<a href="#safe.trainer.collator.SAFECollator.get_tokenizer" class="headerlink" title="Permanent link">&para;</a></h3>


  <div class="doc doc-contents ">
  
      <p>Get underlying tokenizer</p>

          <details class="quote">
            <summary>Source code in <code>safe/trainer/collator.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@functools</span><span class="o">.</span><span class="n">lru_cache</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">get_tokenizer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get underlying tokenizer&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">SAFETokenizer</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">get_pretrained</span><span class="p">()</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>

</div>




  </div>

  </div>

</div><hr />
<h2 id="data-utils">Data Utils<a class="headerlink" href="#data-utils" title="Permanent link">&para;</a></h2>


<div class="doc doc-object doc-module">



<a id="safe.trainer.data_utils"></a>
  <div class="doc doc-contents first">

  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">




<h2 id="safe.trainer.data_utils.get_dataset" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">get_dataset</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">cache_dir</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">streaming</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">use_auth_token</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">tokenize_column</span><span class="o">=</span><span class="s1">&#39;inputs&#39;</span><span class="p">,</span> <span class="n">property_column</span><span class="o">=</span><span class="s1">&#39;descriptors&#39;</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_shards</span><span class="o">=</span><span class="mi">1024</span><span class="p">)</span></code>

<a href="#safe.trainer.data_utils.get_dataset" class="headerlink" title="Permanent link">&para;</a></h2>


  <div class="doc doc-contents ">
  
      <p>Get the datasets from the config file</p>

          <details class="quote">
            <summary>Source code in <code>safe/trainer/data_utils.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_dataset</span><span class="p">(</span>
    <span class="n">data_path</span><span class="p">,</span>
    <span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">cache_dir</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">streaming</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">use_auth_token</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">tokenize_column</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;inputs&quot;</span><span class="p">,</span>
    <span class="n">property_column</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;descriptors&quot;</span><span class="p">,</span>
    <span class="n">max_length</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">num_shards</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get the datasets from the config file&quot;&quot;&quot;</span>
    <span class="n">raw_datasets</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">if</span> <span class="n">data_path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">data_path</span> <span class="o">=</span> <span class="n">upath</span><span class="o">.</span><span class="n">UPath</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">data_path</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">data_path</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
            <span class="c1"># the we need to load from disk</span>
            <span class="n">data_path</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">data_path</span><span class="p">)</span>
            <span class="c1"># for some reason, the datasets package is not able to load the dataset</span>
            <span class="c1"># because the split where not originally proposed</span>
            <span class="n">raw_datasets</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_from_disk</span><span class="p">(</span><span class="n">data_path</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">streaming</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">raw_datasets</span><span class="p">,</span> <span class="n">datasets</span><span class="o">.</span><span class="n">DatasetDict</span><span class="p">):</span>
                    <span class="n">previous_num_examples</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">dt</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">dt</span> <span class="ow">in</span> <span class="n">raw_datasets</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
                    <span class="n">raw_datasets</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">IterableDatasetDict</span><span class="p">(</span>
                        <span class="p">{</span>
                            <span class="n">k</span><span class="p">:</span> <span class="n">dt</span><span class="o">.</span><span class="n">to_iterable_dataset</span><span class="p">(</span><span class="n">num_shards</span><span class="o">=</span><span class="n">num_shards</span><span class="p">)</span>
                            <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">dt</span> <span class="ow">in</span> <span class="n">raw_datasets</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
                        <span class="p">}</span>
                    <span class="p">)</span>
                    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">dt</span> <span class="ow">in</span> <span class="n">raw_datasets</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                        <span class="k">if</span> <span class="n">previous_num_examples</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                            <span class="nb">setattr</span><span class="p">(</span><span class="n">dt</span><span class="p">,</span> <span class="s2">&quot;num_examples&quot;</span><span class="p">,</span> <span class="n">previous_num_examples</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">num_examples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">raw_datasets</span><span class="p">)</span>
                    <span class="n">raw_datasets</span> <span class="o">=</span> <span class="n">raw_datasets</span><span class="o">.</span><span class="n">to_iterable_dataset</span><span class="p">(</span><span class="n">num_shards</span><span class="o">=</span><span class="n">num_shards</span><span class="p">)</span>
                    <span class="nb">setattr</span><span class="p">(</span><span class="n">raw_datasets</span><span class="p">,</span> <span class="s2">&quot;num_examples&quot;</span><span class="p">,</span> <span class="n">num_examples</span><span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="n">raw_datasets</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_dataset</span><span class="p">(</span>
                <span class="n">data_path</span><span class="p">,</span>
                <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
                <span class="n">cache_dir</span><span class="o">=</span><span class="n">cache_dir</span><span class="p">,</span>
                <span class="n">use_auth_token</span><span class="o">=</span><span class="kc">True</span> <span class="k">if</span> <span class="n">use_auth_token</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
                <span class="n">streaming</span><span class="o">=</span><span class="n">streaming</span><span class="p">,</span>
            <span class="p">)</span>
    <span class="c1"># that means we need to return a tokenized version of the dataset</span>

    <span class="k">if</span> <span class="n">property_column</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;mc_labels&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">]:</span>
        <span class="n">raw_datasets</span> <span class="o">=</span> <span class="n">raw_datasets</span><span class="o">.</span><span class="n">rename_column</span><span class="p">(</span><span class="n">property_column</span><span class="p">,</span> <span class="s2">&quot;mc_labels&quot;</span><span class="p">)</span>

    <span class="n">columns_to_remove</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">tokenize_column</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">columns_to_remove</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">x</span>
            <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">(</span><span class="n">get_dataset_column_names</span><span class="p">(</span><span class="n">raw_datasets</span><span class="p">)</span> <span class="ow">or</span> <span class="p">[])</span>
            <span class="k">if</span> <span class="n">x</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="n">tokenize_column</span><span class="p">,</span> <span class="s2">&quot;mc_labels&quot;</span><span class="p">]</span> <span class="ow">and</span> <span class="s2">&quot;label&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">x</span>
        <span class="p">]</span> <span class="ow">or</span> <span class="kc">None</span>

    <span class="k">if</span> <span class="n">tokenizer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">columns_to_remove</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">raw_datasets</span> <span class="o">=</span> <span class="n">raw_datasets</span><span class="o">.</span><span class="n">remove_columns</span><span class="p">(</span><span class="n">columns_to_remove</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">raw_datasets</span>

    <span class="k">return</span> <span class="n">raw_datasets</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
        <span class="n">partial</span><span class="p">(</span>
            <span class="n">tokenize_fn</span><span class="p">,</span>
            <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
            <span class="n">tokenize_column</span><span class="o">=</span><span class="n">tokenize_column</span><span class="p">,</span>
            <span class="n">max_length</span><span class="o">=</span><span class="n">max_length</span><span class="p">,</span>
        <span class="p">),</span>
        <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">remove_columns</span><span class="o">=</span><span class="n">columns_to_remove</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">




<h2 id="safe.trainer.data_utils.get_dataset_column_names" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">get_dataset_column_names</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span></code>

<a href="#safe.trainer.data_utils.get_dataset_column_names" class="headerlink" title="Permanent link">&para;</a></h2>


  <div class="doc doc-contents ">
  
      <p>Get the column names in a dataset</p>



  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>dataset</code></td>
          <td>
                <code><a class="autorefs autorefs-external" title="typing.Union" href="https://docs.python.org/3/library/typing.html#typing.Union">Union</a>[<span title="datasets.Dataset">Dataset</span>, <span title="datasets.IterableDataset">IterableDataset</span>, <a class="autorefs autorefs-external" title="collections.abc.Mapping" href="https://docs.python.org/3/library/collections.abc.html#collections.abc.Mapping">Mapping</a>]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>dataset to get the column names from</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>safe/trainer/data_utils.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_dataset_column_names</span><span class="p">(</span><span class="n">dataset</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">datasets</span><span class="o">.</span><span class="n">Dataset</span><span class="p">,</span> <span class="n">datasets</span><span class="o">.</span><span class="n">IterableDataset</span><span class="p">,</span> <span class="n">Mapping</span><span class="p">]):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get the column names in a dataset</span>

<span class="sd">    Args:</span>
<span class="sd">        dataset: dataset to get the column names from</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="p">(</span><span class="n">datasets</span><span class="o">.</span><span class="n">IterableDatasetDict</span><span class="p">,</span> <span class="n">Mapping</span><span class="p">)):</span>
        <span class="n">column_names</span> <span class="o">=</span> <span class="p">{</span><span class="n">split</span><span class="p">:</span> <span class="n">dataset</span><span class="p">[</span><span class="n">split</span><span class="p">]</span><span class="o">.</span><span class="n">column_names</span> <span class="k">for</span> <span class="n">split</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">}</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">column_names</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">column_names</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">column_names</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="n">column_names</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">column_names</span><span class="o">.</span><span class="n">values</span><span class="p">())[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">column_names</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">




<h2 id="safe.trainer.data_utils.take" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">take</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">iterable</span><span class="p">)</span></code>

<a href="#safe.trainer.data_utils.take" class="headerlink" title="Permanent link">&para;</a></h2>


  <div class="doc doc-contents ">
  
      <p>Return first n items of the iterable as a list</p>

          <details class="quote">
            <summary>Source code in <code>safe/trainer/data_utils.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">take</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">iterable</span><span class="p">):</span>
    <span class="s2">&quot;Return first n items of the iterable as a list&quot;</span>
    <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">itertools</span><span class="o">.</span><span class="n">islice</span><span class="p">(</span><span class="n">iterable</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">




<h2 id="safe.trainer.data_utils.tokenize_fn" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">tokenize_fn</span><span class="p">(</span><span class="n">row</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">tokenize_column</span><span class="o">=</span><span class="s1">&#39;inputs&#39;</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

<a href="#safe.trainer.data_utils.tokenize_fn" class="headerlink" title="Permanent link">&para;</a></h2>


  <div class="doc doc-contents ">
  
      <p>Perform the tokenization of a row
Args:
    row: row to tokenize
    tokenizer: tokenizer to use
    tokenize_column: column to tokenize
    max_length: maximum size of the tokenized sequence
    padding: whether to pad the sequence</p>

          <details class="quote">
            <summary>Source code in <code>safe/trainer/data_utils.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">tokenize_fn</span><span class="p">(</span>
    <span class="n">row</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span>
    <span class="n">tokenizer</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
    <span class="n">tokenize_column</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;inputs&quot;</span><span class="p">,</span>
    <span class="n">max_length</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">padding</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Perform the tokenization of a row</span>
<span class="sd">    Args:</span>
<span class="sd">        row: row to tokenize</span>
<span class="sd">        tokenizer: tokenizer to use</span>
<span class="sd">        tokenize_column: column to tokenize</span>
<span class="sd">        max_length: maximum size of the tokenized sequence</span>
<span class="sd">        padding: whether to pad the sequence</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># there&#39;s probably a way to do this with the tokenizer settings</span>
    <span class="c1"># but again, gotta move fast</span>

    <span class="n">fast_tokenizer</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">tokenizer</span><span class="o">.</span><span class="n">get_pretrained</span><span class="p">()</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">SAFETokenizer</span><span class="p">)</span> <span class="k">else</span> <span class="n">tokenizer</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">fast_tokenizer</span><span class="p">(</span>
        <span class="n">row</span><span class="p">[</span><span class="n">tokenize_column</span><span class="p">],</span>
        <span class="n">truncation</span><span class="o">=</span><span class="p">(</span><span class="n">max_length</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">),</span>
        <span class="n">max_length</span><span class="o">=</span><span class="n">max_length</span><span class="p">,</span>
        <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span>
        <span class="n">return_tensors</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>

</div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright 2023 Valence Labs
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://github.com/datamol-io" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://twitter.com/datamol_io" target="_blank" rel="noopener" title="twitter.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://pypi.org/project/safe-mol/" target="_blank" rel="noopener" title="pypi.org" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.8 200.5c-7.7-30.9-22.3-54.2-53.4-54.2h-40.1v47.4c0 36.8-31.2 67.8-66.8 67.8H172.7c-29.2 0-53.4 25-53.4 54.3v101.8c0 29 25.2 46 53.4 54.3 33.8 9.9 66.3 11.7 106.8 0 26.9-7.8 53.4-23.5 53.4-54.3v-40.7H226.2v-13.6h160.2c31.1 0 42.6-21.7 53.4-54.2 11.2-33.5 10.7-65.7 0-108.6zM286.2 404c11.1 0 20.1 9.1 20.1 20.3 0 11.3-9 20.4-20.1 20.4-11 0-20.1-9.2-20.1-20.4.1-11.3 9.1-20.3 20.1-20.3zM167.8 248.1h106.8c29.7 0 53.4-24.5 53.4-54.3V91.9c0-29-24.4-50.7-53.4-55.6-35.8-5.9-74.7-5.6-106.8.1-45.2 8-53.4 24.7-53.4 55.6v40.7h106.9v13.6h-147c-31.1 0-58.3 18.7-66.8 54.2-9.8 40.7-10.2 66.1 0 108.6 7.6 31.6 25.7 54.2 56.8 54.2H101v-48.8c0-35.3 30.5-66.4 66.8-66.4zm-6.7-142.6c-11.1 0-20.1-9.1-20.1-20.3.1-11.3 9-20.4 20.1-20.4 11 0 20.1 9.2 20.1 20.4s-9 20.3-20.1 20.3z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": ["navigation.expand"], "search": "../assets/javascripts/workers/search.f886a092.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"provider": "mike"}}</script>
    
    
      <script src="../assets/javascripts/bundle.d7c377c4.min.js"></script>
      
    
  </body>
</html>